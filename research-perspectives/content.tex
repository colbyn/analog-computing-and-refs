\subsection{A Future of Medicine, by Dr. Bernard}

% Dr. Bernard, A Future Of Medicine. Heme Review, \url{https://youtu.be/iVt5BpoTHYg}.

In his video essay, A Future of Medicine, Dr. Bernard postulates on a world that views our current system of evidence based medicine, as we see European plague doctors. Because in our modern system of evidence based medicine, we extrapolate population data to a given person, for the purpose of predicting outcome. Which you may ask, what is the problem with such? 

In his talk, he explain two outstanding issues. The first is about a documented ethical dilemma written by the New York Times, called ``New Drugs Stir Debate on Rules of Clinical Trials''. It's about two cousins who happen to develop the same type of cancer. Ultimately both got involved in a clinical trial where one was given the preexisting standard of treatment, and the other, given the new experimental treatment. The issue here is, mortality rate for the preexisting standard of treatment is so grim that one was effectively condemned to death. As his mother said, ``What gives them the right to play God?''\textsuperscript{(Harmon)}

But more relevant to my chosen topic. Efficacy is based on generalizations of the applicable demographic, which doesn’t necessarily accommodate differences between yourself and the general population therefrom. Furthermore, as Dr. Bernard points out, if a trial was done on a bunch of men, clinical experience suggests that there will be differences for women taking the same medication.\textsuperscript{(Bernard)}

Ultimately, what Dr. Bernard is aiming for is a -more ideal- hypothetical replacement to our current standard of evidence based medicine that is founded on computer modeling -technology that, as he points out, will probably not be available in our lifetime.


\subsection{Codebreaker: A deeply personal quest made Matthew Might a leader in precision medicine and brought him to UAB, by Cary Estes}

% Estes, Cary. ``Codebreaker: A deeply personal quest made Matthew Might a leader in precision medicine and brought him to UAB''. \url{https://www.uab.edu/medicine/magazine/178-codebreaker-a-deeply-personal-quest-made-matthew-might-a-leader-in-precision-medicine-and-brought-him-to-uab}.

This is about a very interesting story that isn't very well documented. But perhaps this source may be considered credible since it's by the University of Alabama at Birmingham.

Essentially, it's about a child who was born with a rare genetic disorder that had no known treatments. Why this is relevant to my talk is because this resembles what we may perhaps consider to be the forerunner to Dr. Bernard's hypothetical replacement to our current standard of evidence based medicine that is founded on computer modeling.

In this case, the father of this child, Matt Might, used computation to discover pathways (presumably using open biological databases) that work around a malformed protein. As he put it, in essence, if red increases green, and green decreases blue, then we can decrease blue by increasing red. In this case, he used the Kappa programming language and constructed a model based on a series of constraints that the computer must satisfy. It's regarded as an old form of machine learning, and unlike modern machine learning, the solution isn’t ‘inferred’. As in, ‘how’ it arrives at a given answer will be known.

Now, he’s a Professor, and Department of Medicine Director, at Hugh Kaul Precision Medicine Institute (and he doesn't even have a medical degree, it's in computer science).

\subsection{Analog synthetic biology by Rahul Sarpeshkar}

% Sarpeshkar, R. “Analog synthetic biology.” Philosophical transactions. Series A, Mathematical, physical, and engineering sciences vol. 372,2012 20130110. 24 Feb. 2014, doi:10.1098/rsta.2013.0110

While the above source is an instance of treatment that is perhaps a subset of Dr. Bernard's hypothetical system, this source pertains to the actual computing side. 

The motivations underlying my topic began from a TED-X talk by a man called Rahul Sarpeshkar (Professor of Engineering, Thomas E. Kurtz Professor, Professor of Microbiology \& Immunology, Professor of Physics, Professor of Molecular \& Systems Biology). In his talk, Sarpeshkar discussed the prospects of analog computing for solving differential equations in a manner that far outpaces the capabilities of digital computers, and furthermore, he claimed that we could viably simulate an entire person if we built an analog computer that spanned the size of the given auditorium.

This is due, not to processing performance, but as Sarpeshkar argues, in information theory. That is, digital computation in contrast, while built upon analog mediums, forgoes most of the real estate therein for a limited set of gates defined in terms of a mere bit, in a single multi-bit analog channel. Conversely, in allowing full utilization of the unclaimed and unexploited real estate therefrom, in further expanding our conception of computation to more than mere logic, new applications may potentially become commercially viable. Such as perhaps, simulating the molecular interactions within cells, to tissues, to entire organ systems, to perhaps, entire persons.

Or rather, as Sarpeshkar summarized:

\begin{quotation}
    ``[at] low informational precision, logic basis functions simply cannot compete with the richer basis functions of analog computation that can process all the bits at once in parallel and just automatically solve the task, e.g. by using Kirchoff’s current law for addition or chemical binding for multiplication.''\textsuperscript{(Sarpeshkar)}
\end{quotation}


The central issue plaguing analog computers is that of precision. Analog computations are typically bounded to just three or four bits of precision. Yet, advocates of analog computers argue that many problems do not exceed such limitations, and therefore permits implementation in an analog environment that affords a greater degree of optimizations that aren't possible on digital computer architectures. 

In this context, Sarpeshkar argues that the fundamental limitations of analog computing, notably, noisy signals, is ideal for simulating stochastic process. Because simulating randomness on digital hardware imposes synchronization constraints that significantly impacts performance on such systems. Whereas on analog architectures, Sarpeshkar argues, you essentially get such for free.

Furthermore, the author postulates that there exists a deep connection between electrons and chemistry, in the sense that we can define an isomorphism (my own words) between the chemistry that manifests real life, and modeling the very same systems `electronically'. 



\subsection{Analog synthetic biology by Rahul Sarpeshkar}

While the above source is an instance of treatment that is perhaps a subset of Dr. Bernard's hypothetical system, it is still far from the idealized picture described therefrom. Yet, there is speculation that simulating an entire person may be possible.

I first heard about such speculations from a TED-X talk by a man called Rahul Sarpeshkar (Professor of Engineering, Thomas E. Kurtz Professor, Professor of Microbiology \& Immunology, Professor of Physics, Professor of Molecular \& Systems Biology). In his talk, Sarpeshkar discussed the prospects of analog computing for solving differential equations in a manner that far outpaces the capabilities of digital computers, and furthermore, he claimed that we could viably simulate an entire person if we built an analog computer that spanned the size of the given auditorium.

The reason for our fixation on differential equations is because this is the mathematical framework in which we typically model systems in nature. But not just the sciences, such is also pervasive throughout engineering, including electrical circuits. Therefore, as I like to imagine, it's not too much of a stretch to go from modeling to simulation.

% But from another perspective on the rationale, there are systems that cannot be defined any other way. Or as Grant Sanderson (from the 3Blue1Brown channel on YouTube) put it (paraphrasing here), one may not be able to quantify their feelings of love for another person, but the fluctuations therein can nevertheless be defined by means of such a framework, and therefore, math nevertheless gives us a framework to study the unsolvable. 

But returning back to the discussion of simulation efficiency. This is possible, it is argued, because analog computing can be made to simulate natural systems in a manner that is significantly more efficient than it's digital counterparts. That is, Sarpeshkar argues, more efficient in terms of energy, time (computation) and space (memory and program installation). 

The negative side of analog computing lies in precision, and this is typically bounded to just three or four bits of precision. But, in this manner, Sarpeshkar argues that precision is correlated to higher energy consumption (with a given equation for such), and therefore, low precision affording operations as such, and this itself is the cause for much of the power efficiency of cells, and for potential optimizations on analog architectures. 

But from the perspective of simulating such systems on electronic analog systems, the author likewise argues that the noise interference that has traditionally encumbered analog computing is, in fact, a benefit. This is because when running stochastic processes, we essentially get randomness for free. This is in contrast to simulating randomness in digital computers, which imposes significant comparative overhead. 

% ``There is a deep connection between ‘electronics’, which is about the controlled, relatively long-range motions of electrons be- tween devices, and ‘chemistry’, which is about the controlled, relatively short-range motions of electrons between atoms and molecules. ''\textsuperscript{(Teo)}


% \subsection{Synthetic Biology: A Unifying View and Review Using Analog Circuits by Jonathan J. Y. Teo}


% Teo argues that while the component parts of cells are discrete, they do not operate in terms of discrete 





